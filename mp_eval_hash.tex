% !TEX root=./tech-specification.tex

\section{Multi-point Evaluation Hashing}
\label{app:mp_eval_hash}

%% Rust code reference
%  Tag: v1.0-alpha
%  Base Dir: core/src/pow 

\subsection{Definitions}
We employ the following definitions:

\begin{tabu*}{lcl}
\toprule
Name & Value & Description \\
\midrule
\linkdest{J__wordbytes}{}$J_{wordbytes}$ & $4$  & Bytes in word. \\
% shared.rs:3
\linkdest{J__datasetinit}{}$J_{datasetinit}$ & $ 2^{32}$ & Bytes in dataset at genesis. \\
% shared.rs:4
\linkdest{J__datasetgrowth}{}$J_{datasetgrowth}$ & $2^{24}$ & Dataset growth per stage. \\
% shared.rs:5
\linkdest{J__cacheinit}{}$J_{cacheinit}$ & $2^{24}$ & Bytes in cache at genesis. \\
% shared.rs:6
\linkdest{J__cachegrowth}{}$J_{cachegrowth}$ & $2^{16}$ & Cache growth per stage. \\
% shared.rs:8
\linkdest{J__stage}{}$J_{stage}$ & $2^{19}$ & Epoches per stage. \\
% shared.rs:9
\linkdest{J__cacherounds}{}$J_{cacherounds}$ & $3$ & Number of rounds in cache production. \\
% shared.rs:10
\linkdest{J__mixbytes}{}$J_{mixbytes}$ & $256$ & mix length in bytes. \\
% shared.rs:23
\linkdest{J__hashbytes}{}$J_{hashbytes}$ & $64$ & Hash length in bytes. \\
\linkdest{J__parents}{}$J_{parents}$ & $256$ & Number of parents of each dataset element. \\
% shared.rs:17
\linkdest{J__pow}{}$J_{pow}$ & $2^{10}$ & Degree of polynomial in multiple point evaluation. \\
% shared.rs:19
\linkdest{J__accesses}{}$J_{accesses}$ & $2^5$ & Number of accesses in hashimoto loop. \\
% shared.rs:18
\linkdest{J__warpsize}{}$J_{warpsize}$ & $J_{pow}/J_{accesses}$ &  \\
\linkdest{J__mod}{}$J_{mod}$ & $1032193$ & Modulus in multiple point evaluation. \\
\bottomrule
\end{tabu*}

\subsection{Size of Dataset and Cache}
The size for the hash function's cache $\mathbf{c} \in \B^*$  and dataset $\mathbf{d} \in \B^*$ depend on the stage, which in turn depends on the block height $\head_{h}$.
\begin{equation} % cache.rs:44
 E_{stage}(\head_{h}) \eqdef \left\lfloor\frac{\head_{h}}{J_{stage}}\right\rfloor
\end{equation}
The size of the dataset growth by $J_{datasetgrowth}$ bytes, and the size of the cache by $J_{cachegrowth}$ bytes, every stage. In order to avoid regularity leading to cyclic behavior, the size must be a prime number. Therefore the size is reduced by a multiple of $J_{mixbytes}$, for the dataset, and $J_{hashbytes}$ for the cache.
\linkdest{d__size}{}Let $d_{size} = \lVert\dataset \rVert$ be the size of the dataset, 
which is calculated using
% shared:52
\begin{equation}
 d_{size} \eqdef E_{\mathrm{prime}}(J_{datasetinit} + J_{datasetgrowth} \cdot E_{stage}, J_{mixbytes})
\end{equation}
The size of the cache, $c_{size}$, is calculated using
% shared:41
\begin{equation}
 c_{size} \eqdef E_{\mathrm{prime}}(J_{cacheinit} + J_{cachegrowth} \cdot E_{stage}, J_{hashbytes})
\end{equation}
where $E_{\mathrm{prime}}(x, y)$ asserts $x/y$ is an integer and returns the largest number $x'$ such that $x'<x$ and $x'=p\cdot y$ for some prime number $p$. 
% shared:45
% shared:56
\begin{equation}
	E_{\mathrm{prime}}(x, y) \eqdef \max_{x'<x\;\wedge\;\mathsf{IsPrime}(x'/y)} x'
\end{equation}
\subsection{Stage Dataset Generation}
In order to generate the dataset $\dataset$ for stage $J_{stage}$, we need the cache $\mathbf{c}$, which is an array of bytes. It depends on the cache size  $c_{size}$ and the seed hash $\mathbf{s} \in \B_{256}$.
\subsubsection{Seed hash}
The seed hash is different for every stage. For the first stage it is the Keccak-256 hash of a series of 256 bits (32 bytes) of zeros. For every other stage it is always the Keccak-256 hash of the previous seed hash:
% seed_compute.rs:27
% seed_compute.rs:45
\begin{equation}
 \mathbf{s} \eqdef \kec^{(E_{stage}(\head_h))}(\mathbf{0}_{256})
\end{equation}
where $\mathbf{0}_{256}$ denotes $256$ bits of zeros. (Recalling that $f^{(n)}$ represents calling function $f$ in $n$ times recursively.)

\subsubsection{Cache}
The cache production process involves using the seed hash to first sequentially filling up $c_{size}$ bytes of memory, then performing $J_{cacherounds}$ passes of the RandMemoHash algorithm created by \cite{lerner2014randmemohash}. The initial cache $\mathbf{c'}$ will be constructed as follows.

Recalling that $\kec512$ denotes the Keccak-512 hash function whose output length is $512$ bits ($64$ single bytes), 
we define initial cache $\mathbf{c'}$ can be defined as:
\begin{equation}
 \mathbf{c'}[i] \eqdef \kec512^{(i)}(\mathbf{s}), \quad \forall \quad i \in\set{0,1,2,\dots, n-1}
\end{equation}
where $n$ denote the number of elements in cache:
\begin{equation}
	n \eqdef  c_{size}/J_{hashbytes}
\end{equation}

The cache $\mathbf{c}$,
consisting of $n$ items of $\kec512$ hash values, 
is calculated by performing $J_{cacherounds}$ rounds of the RandMemoHash algorithm to the initial cache $\mathbf{c'}$:
\begin{equation}
 \mathbf{c} \eqdef E_\text{\tiny RMH}^{(J_{cacherounds})}(\mathbf{c'})
\end{equation}


Every single round of the RandMemoHash algorithm modifies each subset of the cache as follows:
% cache.rs:110
\begin{align}
	E_\text{\tiny RMH}(\mathbf{x}) &\eqdef \big( E_{rmh}(\mathbf{x}, 0), E_{rmh}(\mathbf{x}, 1), ... , E_{rmh}(\mathbf{x}, n - 1) \big)\linkdest{E__cacherounds}{}  \\
	E_{rmh}(\mathbf{x}, i) &\eqdef \kec512(\mathbf{x'}[(i - 1 + n) \mod n] \oplus \mathbf{x'}[\mathbf{x'}[i][0] \mod n]) \quad
	\text{with} \quad \mathbf{x'}[j] = 
	\begin{cases}
		E_{rmh}(\mathbf{x}, j) & j<i \\ 
		\mathbf{x}[j] & j\ge i
	\end{cases}
\end{align}
where $\mathbf{x'}[i][0]$ denotes the first word of $\mathbf{x'}[i]$.

\subsubsection{Full dataset calculation} \label{app:dataset}
Essentially, we combine data from $J_{parents}$ pseudorandomly selected cache nodes, and hash that to compute the dataset. The entire dataset $\dataset$ is then generated by a number of items, each of $J_{hashbytes}$ bytes in size:
% compute.rs:409
\begin{equation}
\dataset[i] \eqdef E_{datasetitem}(\mathbf{c}, i) \quad \forall \quad 0\le i < d_{size}/J_{hashbytes} 
\end{equation}
In order to calculate the single item we use an algorithm $\fnv:\N_{32}\times\N_{32} \to \N_{32}$ inspired by the FNV hash \cite{FowlerNollVo1991FNVHash} in some cases as a non-associative substitute for XOR.
\begin{equation}
	\fnv(\mathbf{x}, \mathbf{y}) \eqdef \left( (\mathbf{x} \times \mathrm{0x01000193}) \oplus \mathbf{y}\right) \mod 2^{32}
\end{equation}
When $\fnv$ receives input in $\B_{32}$, it interprets it as a little-endian encoding integer in $\N_{32}$.

The single item of the dataset can now be calculated by iteratively mixing items from the cache $\mathbf{c}$ as follows:
% compute.rs:430
\begin{equation}
 E_{datasetitem}(\mathbf{c}, i) \eqdef 
 \kec512\Big(\mathbf{m}_{J_{parents}}\Big)
\end{equation}
where $\mathbf{m}_{j}$ is updated from $\mathbf{m}_{j-1}$ by function $E_{mix}$. $\mathbf{m}_0$ is initialized with the hash value computed from cache $\mathbf{c}$ and index $i$.
\begin{align}
	% compute.rs:420-427
	\mathbf{m}_j &\eqdef E_{mix}(\mathbf{c}, i, \mathbf{m}_{j-1},j-1) \quad \forall 1\le j \le J_{parents} \\
	% compute.rs:411-416
	\mathbf{m}_0 &\eqdef \kec512(\mathbf{c}[i\mod n] \oplus i) \\
	E_{mix}(\mathbf{c}, i, \mathbf{m},p) & \eqdef \fnv^*\Big(\mathbf{m}, \mathbf{c}[\fnv(i \oplus p, ~ \mathbf{m}\big[p \mod J_{hashbytes} / J_{wordbytes} ]) \mod n \big] \Big)
\end{align}
Here, $i$ is regarded as a 512-bit string in little-endian
and $\fnv^*$ denotes the element-wise invocation of $\fnv$ over $J_{hashbytes}$-bit string, which is interpreted as an array of words in little-endian. 

\subsection{Proof-of-work function}
\label{appsec:pow}

Essentially, we maintain a ``mix'' of $J_{mixbytes}$ bytes wide, and repeatedly sequentially fetch $J_{mixbytes}$ bytes from the full dataset and use the $\fnv$ function to combine it with the mix. 
$J_{mixbytes}$ bytes of sequential access are used so that each round of the algorithm always fetches a full page from RAM, minimizing translation lookaside buffer misses which ASICs would theoretically be able to avoid.

If the output of this algorithm is below the desired target, then the nonce is valid. Note that the extra application of $\kec$ at the end ensures that there exists an intermediate nonce which can be provided to prove that at least a small amount of work was done; this quick outer PoW verification can be used for anti-DDoS purposes. It also serves to provide statistical assurance that the result is an unbiased, 256 bit number.

The $\mpethash$ function takes $\headernon$, which is the hash of the header excluding the {\bf nonce} fields,
i.e. $\headernon\eqdef \kec\left(\rlp( \head_{-n} )\right)$,
together with the nonce $\head_{n}$
and the dataset $\dataset$ from \cref{app:dataset} as input.
The output of $\mpethash$ is the Keccak-256 hash of the concatenation of the seed hash $\seedhash\in \B_{512}$ and the compressed mix $\compressedmix\in \B_{256}$:
\begin{equation}
	\mpethash(\headernon, \head_{n},\dataset) \eqdef 
	 \kec\left(\seedhash \circ \compressedmix \right)
\end{equation}

\subsubsection{Multi-point mix}
The multi-points $\mppnt\in \N_{64}^{J_{accesses}}$ and multi-point mix $\mpmix\in \N_{64}$ is calculated from the header $\headernon$, $\head_n$ as follows:
\begin{align}
	\mppnt &\eqdef \mppnt\left( \headernon, \head_n \right) \eqdef E_{mp-eval}(a,b,c,w,n_{low},\vec{z})\\
	\mpmix &\eqdef \mpmix\left( \mppnt \right) \eqdef  E_{\text{\tiny FNV}-compress}\left(\mppnt,J_{accesses} \right)
\end{align}
with arguments and functions described in the rest of this section.

Interpreting $\headernon$ as a 4-element array of $\N_{64}$ encoded in little-endian, 
input arguments $a,b,c,w\in \N_{64},n_{low}\in \N$ are defined as follows:
% compute.rs:206
\begin{align}
	a &\eqdef E_{remap}(\headernon[0])\\
	b &\eqdef E_{remap}(\headernon[1])\\
	c &\eqdef E_{remap}(E_{proper\_c}(a,b,\headernon[2]))\\
	w &\eqdef E_{remap}(\headernon[3])\\
	n_{high} &\eqdef \lfloor(\head_n \mod 2^{64})/J_{warpsize}\rfloor \\
	n_{low} &\eqdef \head_n \mod J_{warpsize}
\end{align}
where 
% compute.rs:161
\begin{align}
	E_{proper\_power}(h) &\eqdef \argmax_{x| h \;\land\;\mathsf{gcd}(x,J_{mod}-1)=1} x \\
	E_{remap}(h) &\eqdef 11^{E_{proper\_power}((h {\scriptsize \mod} (J_{mod}-2)) + 1)}  \mod J_{mod} \\
	E_{proper\_c}(a,b,h) &\eqdef \argmin_{x\ge h \;\land\; J_{mod}\nmid b^2-4a\cdot E_{remap}(x)} x
\end{align}

The last argument $\vec{z}$ is an array of $J_{pow}=J_{accesses}\times J_{warpsize}$ items drawn from $\N_{32}$.
More specifically, $\vec{z}[i]$ is defined as:
% compute.rs:212
\begin{equation}
	\vec{z}[i\cdot J_{warpsize} + j] \eqdef E_{\text{\tiny Sip},2,j+4}\left((n_{high}\cdot J_{warpsize}+j)\mod 2^{64}\right) \mod J_{mod} \quad
	 \forall 0\le i<J_{accesses}, 0\le j < J_{warpsize}
\end{equation}
where the $E_{\text{\tiny Sip},c,d}$ refers the SipHash-$c$-$d$ function with a different key initialization process by $v_i \eqdef \headernon[i]$ ($i\in\{0,1,2,3\}$). See~\cite{aumasson2012siphash} for more details about SipHash function.

The multiple points $\mppnt$ is an array of 32-bit $J_{accesses}$ integers. Function $E_{mp-eval}$ evaluated the polynomial $E_{polynomial}$ on multiple points $\vec{x}[i]$ for $i\in \set{0,1,\dots, J_{accesses}-1}$ to get $\mppnt$.
% compute.rs:242
\begin{equation}
	E_{mp-eval}(a,b,c,w,n_{low},\vec{z}) \eqdef 
	\left\{E_{polynomial}\left(\vec{x}[0]\right) , E_{polynomial}\left(\vec{x}[1]\right) , \cdots ,
	E_{polynomial}\left(\vec{x}[J_{accesses}-1]\right)\right\}
\end{equation}
where $\vec{x}$ is an array of words defined as:
% compute.rs:226-251
\begin{align}
	\vec{x}[i] &\eqdef c+b\cdot w^{i\cdot J_{warpsize} + n_{low}} + a\cdot w^{2\cdot (i\cdot J_{warpsize} + n_{low})}, \quad \forall \quad 0\le i \le J_{accesses}-1 
\end{align}
and the $E_{polynomial}$ function is a polynomial with coefficients specified by $\vec{z}$:
\begin{equation}
	E_{polynomial}(x) \eqdef \left(\sum_{j=0}^{J_{pow}-1} \vec{z}[j]\cdot x^j\right) \mod J_{mod}
\end{equation}

The FNV-compress function $E_{\text{\tiny FNV}-compress}$ is defined over $\left(\N_{32}\right)^* \times \N \to \N_{64}$ 
and used to compress an array of $\N_{32}$ elements into a single $\N_{64}$ element:
\begin{equation}
	E_{\text{\tiny FNV}-compress}(\vec{p},i) \eqdef 
	\begin{cases}
		\vec{0}_{64} & \text{if} \quad i < 1 \\
		E_\text{\tiny FNV64}\left( 
		E_{\text{\tiny FNV}-compress}(\vec{p},i-1) ,
		\vec{p}[i-1]\right)
		& \text{otherwise}
	\end{cases}
\end{equation}
where integers in $\N_{32}$ are interpreted as integers in $\N_{64}$, $E_\text{\tiny FNV64}: \N_{64}\times \N_{64} \rightarrow \N_{64}$ naturally extends $\fnv$.
% compute.rs:45
\begin{equation}
	E_\text{\tiny FNV64}(\mathbf{x}, \mathbf{y}) \eqdef \left( (\mathbf{x} \times \mathrm{0x01000193}) \oplus \mathbf{y}\right) \mod 2^{64}
\end{equation}

\subsubsection{Half mix}
The half mix $\seedhash\in \B_{512}=\Byte_{J_{hashbytes}}$ is defined on $\headernon$ and $\mpmix$ as follows:
% compute.rs:292
\begin{equation}
 \seedhash \eqdef 
 \seedhash(\headernon, \mpmix) \eqdef \kec512\left(\headernon \circ \mathrm{LE}(\mpmix)\right)
\end{equation}
where $\mathrm{LE}(\mpmix)$ returns the little-endian encoding of the compressed multi-point mix $\mpmix$.

\subsubsection{Compressed mix}
The compressed mix $\compressedmix \in \B_{256}$ is obtained from the seed hash $\seedhash\in \B_{512}=\Byte_{J_{hashbytes}}$, the dataset $\dataset\in \Byte_{d_{size}}$ and the multiple points $\mppnt\in (\N_{64})^{J_{accesses}}$:
\begin{equation}\label{eq:compress}
 \compressedmix \eqdef 
 \compressedmix\big(\seedhash,\dataset,\mppnt) \eqdef E_{compress}\big(\mathbf{m}_{J_{accesses}}\big)
\end{equation}
where $\mathbf{m}_{J_{accesses}}$ and $E_{compress}$ are defined as follows.

The initial mix $\mathbf{m}_0$ is an array of $n_{mixw}$ words 
obtained by replicating the seed hash $\seedhash$ for $n_{mixh}$ times, 
with $n_{mixw},n_{mixh}$ defined as:
\begin{align}
	n_{mixw}& \eqdef  \frac{J_{mixbytes}}{J_{wordbytes}}\\
	n_{mixh}& \eqdef  \frac{J_{mixbytes}}{J_{hashbytes}}
\end{align}
Formally, the initial mix 
$\mathbf{m}_0 \in \Byte_{J_{mixbytes}}
=\left(\Byte_{J_{wordbytes}}\right)^{n_{mixw}}$ is defined as:
\begin{equation}
	\mathbf{m}_0 \eqdef \underbrace{\seedhash \circ \cdots \circ \seedhash}_{\text{$n_{mixh}$ many copies of $\seedhash$}}
\end{equation}
%
Every the $\mathbf{m}_j$ is updated from $\mathbf{m}_{j-1}$ as follows
% compute.rs:350
\begin{align}
 \mathbf{m}_j[i] &\eqdef 
	\fnv\big(
		\mathbf{m}_{j-1}[i], 
		\mathbf{d}\left[
			\left(p_j\cdot n_{mixh} +\lfloor i/n_{hashw}\rfloor \right) \mod 2^{32}
		\right][i\mod n_{hashw}]
	\big) \quad \forall 0\le j<J_{accesses},0\le i< n_{mixw}\\ 
 {p}_j &\eqdef 
	\fnv\left(j \oplus \seedhash[0] \oplus \mathbf{p}[j], \mathbf{m}_{j-1}\left[j \mod n_{mixw}\right]\right) \mod \frac{d_{size}}{J_{mixbytes}}\quad \forall 0\le j<J_{accesses}
\end{align}
where $n_{hashw}\eqdef J_{hashbytes}/J_{wordbytes}$. We regard a $J_{hashbytes}$-bit string as an array of $n_{hashw}$ words here. 
% where $\fnv^*$ denotes the element-wise invocation of $\fnv$ on $32$-bit elements,
% and $E_{newdata}$ returns an array consisting of $n_{mixh}$ elements from the dataset $\dataset$ (so that the array is of same length as the intermediate mix $\mathbf{m}$, i.e. each of $J_{mixbytes} = n_{mixh}\cdot J_{hashbytes}$ bytes):
% % compute.rs:345
% \begin{equation}
%  	E_{newdata}(\mathbf{d}, \mathbf{m}, \mathbf{s}, i)[j] 
%  	\eqdef \dataset\left[ {p}_i \cdot n_{mixh} + j\right], \quad \forall \quad 0\le j \le n_{mixh}-1
% \end{equation}
% with the mixing index ${p}$ obtained as follows:
% \begin{equation}
% 	{p}_i \eqdef 
% 	\fnv\left(i \oplus \seedhash[0] \oplus \mathbf{p}[i], \mathbf{m}\left[i \mod \left\lfloor\frac{J_{mixbytes}}{J_{wordbytes}}\right\rfloor\right]\right) \mod \left\lfloor\frac{d_{size} / J_{hashbytes}}{n_{mixh}}\right\rfloor
% \end{equation}

The $E_{compress}$ function converts $J_{mixbytes}$-byte mix,
which is an array of $n_{mixw}=64$ words,
into an 8-word array, with the $i$-th word is define as follows:
\begin{multline}
	E_{compress}(\mathbf{m})[i] \eqdef \fnv\big(\fnv(\fnv(\fnv(\mathbf{m}[4i], \mathbf{m}[4i + 1]), \mathbf{m}[4i + 2]), \mathbf{m}[4i + 3]), \\
	\fnv(\fnv(\fnv(\mathbf{m}[4i+32], \mathbf{m}[4i +33]), \mathbf{m}[4i + 34]), \mathbf{m}[4i + 35])\big)\quad \forall 0\le i \le 7
\end{multline}
The array obtained by applying $E_{compress}$ on $m_{J_{accesses}}$ is indeed the compressed mix $\compressedmix$ by \cref{eq:compress}.


